# ğŸ“Š **GUIA DE DADOS - PROJETO AIRBNB**

## ğŸš¨ **ARQUIVOS GRANDES NÃƒO INCLUSOS NO REPOSITÃ“RIO**

### ğŸ“ **Dados Brutos (`data/raw/`)**
Os seguintes arquivos CSV **NÃƒO estÃ£o inclusos** no repositÃ³rio devido ao tamanho (>100MB cada):

```
abril2018.csv      â†’ 117.85 MB
maio2018.csv       â†’ 117.35 MB  
julho2018.csv      â†’ 115.85 MB
fevereiro2020.csv  â†’ 114.39 MB
agosto2018.csv     â†’ 114.07 MB
maro2020.csv       â†’ 113.04 MB
maro2019.csv       â†’ 112.67 MB
abril2019.csv      â†’ 112.03 MB
abril2020.csv      â†’ 111.88 MB
maio2019.csv       â†’ 111.69 MB
setembro2018.csv   â†’ 111.57 MB
fevereiro2019.csv  â†’ 111.41 MB
maio2020.csv       â†’ 111.33 MB
junho2019.csv      â†’ 111.29 MB
julho2019.csv      â†’ 110.53 MB
janeiro2020.csv    â†’ 109.79 MB
janeiro2019.csv    â†’ 109.58 MB
dezembro2019.csv   â†’ 109.57 MB
outubro2018.csv    â†’ 109.31 MB
... (demais arquivos)
```

### ğŸ¤– **Modelo Treinado**
- **`modelo.joblib`** â†’ **593.04 MB** (arquivo do modelo RandomForest treinado)

## ğŸ“¥ **COMO OBTER OS DADOS**

### **OpÃ§Ã£o 1: Download Direto**
Os dados originais podem ser obtidos do **Inside Airbnb**:
- ğŸŒ **Site**: http://insideairbnb.com/get-the-data.html
- ğŸ“ **Cidade**: Rio de Janeiro, Brazil
- ğŸ“… **PerÃ­odo**: 2018-2020

### **OpÃ§Ã£o 2: Script de Download**
Execute o script de download automÃ¡tico:
```bash
python scripts/download_data.py
```

### **OpÃ§Ã£o 3: Dados Processados**
Para desenvolvimento rÃ¡pido, use a amostra incluÃ­da:
- âœ… `data/processed/primeiros_registros.csv` (incluÃ­do no repo)

## ğŸ”§ **REPRODUÃ‡ÃƒO DO MODELO**

### **1. Instalar DependÃªncias**
```bash
pip install -r requirements.txt
```

### **2. Executar Treinamento**
```bash
python train_model.py
```
ou use o notebook:
```bash
jupyter notebook notebooks/1_analise_e_treinamento.ipynb
```

### **3. Regenerar Modelo**
```bash
python quick_train.py  # Treinamento rÃ¡pido
```

## ğŸ“ **ESTRUTURA RECOMENDADA**

```
airbnb/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Dados originais (GRANDES - nÃ£o no git)
â”‚   â”‚   â”œâ”€â”€ *.csv           # ~110MB cada
â”‚   â””â”€â”€ processed/           # Dados processados
â”‚       â”œâ”€â”€ dados.csv       # Dataset completo (GRANDE - nÃ£o no git)
â”‚       â””â”€â”€ primeiros_registros.csv  # Amostra (incluÃ­do)
â”œâ”€â”€ notebooks/              # Jupyter notebooks (incluÃ­dos)
â”œâ”€â”€ src/                    # CÃ³digo fonte (incluÃ­do)
â”œâ”€â”€ modelo.joblib          # Modelo treinado (GRANDE - nÃ£o no git)
â”œâ”€â”€ requirements.txt       # DependÃªncias (incluÃ­do)
â””â”€â”€ README.md             # DocumentaÃ§Ã£o (incluÃ­do)
```

## âš¡ **DESENVOLVIMENTO LOCAL**

### **Setup Inicial**
1. Clone o repositÃ³rio
2. Instale dependÃªncias: `pip install -r requirements.txt`
3. Baixe os dados (OpÃ§Ã£o 1, 2 ou 3 acima)
4. Execute o notebook de anÃ¡lise

### **ModificaÃ§Ãµes**
- âœ… **Commitar**: CÃ³digo, notebooks, documentaÃ§Ã£o
- âŒ **NÃƒO commitar**: CSVs grandes, modelo.joblib, dados processados

## ğŸ¯ **PRODUÃ‡ÃƒO E DEPLOY**

Para produÃ§Ã£o, considere:
- **â˜ï¸ Cloud Storage**: AWS S3, Google Cloud Storage
- **ğŸ¤– Model Registry**: MLflow, Weights & Biases
- **ğŸ“¦ Model Serving**: Docker + API
- **ğŸ”„ CI/CD**: GitHub Actions para retreinamento automÃ¡tico

---

> **ğŸ’¡ Dica**: Este projeto foca na **reprodutibilidade** e **colaboraÃ§Ã£o**. Os dados e modelos grandes ficam fora do Git, mas o cÃ³digo para recriÃ¡-los estÃ¡ incluso!